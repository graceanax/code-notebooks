# Si es relacionado a datos

* Experiencia relevante en Python con datos.
* Dominio de SQL y bases de datos no relacionales.
* Conocimiento en tecnologías de ETL.
* Capacidades de documentación de negocio y tecnológica.
* Habilidades de priorización de requerimientos y resultados de negocio.
* Experiencia en proyectos BI y modelando bases de datos para Data Warehouse (Estrella, Copo de nieve).



* Experiencia en Cloud (AWS, Azure, GCP), nosotros usamos AWS
* Nivel de inglés Intermedio - Avanzado
* Experiencia en metodologías ágiles como Scrum
* Git



* Conocimiento del stack de tecnologías big data
* Experiencia en soluciones Cloud como AWS o Azure.
* Experiencia en proyectos ETL/ELT , desarrollo y mantención de pipeline de datos
* Trabajo con herramientas de visualización y BI
* Desarrollo de bases de datos relacionales y procesamiento en streaming



* Ingesta y consumo / procesamiento de datos.
* Lenguaje de programación como Python + PySpark.
* Ideal experiencia en Base de datos como SQL y/o MySQL



* Capacidades de desarrollo demostrables en Spark y Python
* Tener al menos 2 años de experiencia en el cargo
* Título de Ingeniero en Computación, T.I., Informática o similar
* Conocimiento en Pyspark, SQL, bases de datos, ingeniería de datos
* Conocimiento de herramientas y prácticas de Git, SSMS, Visual Studio y Docker Hub
* Que cuentes con disponibilidad para trabajar de manera híbrida (teletrabajo y oficina)



* Creación de pipelines de carga y transformación de datos.
* Modelamiento de datos y creación de Data Warehouse y Data Lakes.
* Integración de sistemas.
* Creación de modelos de machine learning con herramientas low code autoML.
